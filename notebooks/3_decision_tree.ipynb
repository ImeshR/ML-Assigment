{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2de86b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9815168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (607346, 22)\n",
      "\n",
      "First 5 rows:\n",
      "   DAY_OF_MONTH  DAY_OF_WEEK OP_UNIQUE_CARRIER  OP_CARRIER_AIRLINE_ID  \\\n",
      "0             1            3                EV                  20366   \n",
      "1             1            3                EV                  20366   \n",
      "2             1            3                EV                  20366   \n",
      "3             1            3                EV                  20366   \n",
      "4             1            3                EV                  20366   \n",
      "\n",
      "  OP_CARRIER TAIL_NUM  OP_CARRIER_FL_NUM  ORIGIN_AIRPORT_ID  \\\n",
      "0         EV   N48901               4397              13930   \n",
      "1         EV   N16976               4401              15370   \n",
      "2         EV   N12167               4404              11618   \n",
      "3         EV   N14902               4405              10781   \n",
      "4         EV   N606UX               4407              14524   \n",
      "\n",
      "   ORIGIN_AIRPORT_SEQ_ID ORIGIN  ...  DEST  DEP_TIME DEP_DEL15  DEP_TIME_BLK  \\\n",
      "0                1393007    ORD  ...   GRB    1003.0       0.0     1000-1059   \n",
      "1                1537002    TUL  ...   ORD    1027.0       0.0     1000-1059   \n",
      "2                1161802    EWR  ...   TYS    1848.0       0.0     1800-1859   \n",
      "3                1078105    BTR  ...   IAH    1846.0       0.0     1800-1859   \n",
      "4                1452401    RIC  ...   IAH    1038.0       0.0     1000-1059   \n",
      "\n",
      "   ARR_TIME ARR_DEL15  CANCELLED  DIVERTED  DISTANCE  Unnamed: 21  \n",
      "0    1117.0       0.0        0.0       0.0     174.0          NaN  \n",
      "1    1216.0       0.0        0.0       0.0     585.0          NaN  \n",
      "2    2120.0       0.0        0.0       0.0     631.0          NaN  \n",
      "3    2004.0       0.0        0.0       0.0     253.0          NaN  \n",
      "4    1330.0       0.0        0.0       0.0    1157.0          NaN  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(\"../data/Jan_2020_ontime.csv\")\n",
    "\n",
    "# Basic data exploration\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f905ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in key columns\n",
    "data = data.dropna(subset=['DEP_TIME', 'OP_UNIQUE_CARRIER', 'DEP_DEL15'])\n",
    "\n",
    "# Create departure hour feature\n",
    "data['DEP_HOUR'] = data['DEP_TIME'].apply(lambda x: int(x/100))\n",
    "\n",
    "# Select features\n",
    "X = data[['DAY_OF_WEEK', 'DEP_HOUR', 'OP_UNIQUE_CARRIER']]\n",
    "y = data['DEP_DEL15']\n",
    "\n",
    "# Convert categorical features to dummy variables\n",
    "X = pd.get_dummies(X, columns=['OP_UNIQUE_CARRIER'], drop_first=True)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save original features for analysis (before any preprocessing)\n",
    "original_test_data = data.loc[X_test.index, ['OP_UNIQUE_CARRIER', 'DEP_HOUR']]\n",
    "\n",
    "# Train Decision Tree model\n",
    "print(\"\\nTraining Decision Tree model...\")\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=5,           # Limit depth to prevent overfitting\n",
    "    min_samples_split=50,  # Minimum samples required to split a node\n",
    "    min_samples_leaf=20,   # Minimum samples required at a leaf node\n",
    "    random_state=42\n",
    ")\n",
    "dt_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f093016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# Visualize the decision tree (limited to max_depth=3 for clarity)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dt_model, \n",
    "          max_depth=3, \n",
    "          feature_names=X_train.columns,\n",
    "          class_names=['Not Delayed', 'Delayed'],\n",
    "          filled=True, \n",
    "          rounded=True, \n",
    "          fontsize=10)\n",
    "plt.title('Decision Tree Visualization (Limited to Depth 3)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8ba961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': dt_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance.head(10))\n",
    "plt.title('Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze performance by carrier\n",
    "# Create results DataFrame with original carrier information\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test.values,\n",
    "    'Predicted': y_pred,\n",
    "    'Carrier': original_test_data['OP_UNIQUE_CARRIER'].values,\n",
    "    'Hour': original_test_data['DEP_HOUR'].values\n",
    "})\n",
    "\n",
    "# Calculate accuracy by carrier\n",
    "carrier_accuracy = results_df.groupby('Carrier').apply(\n",
    "    lambda x: accuracy_score(x['Actual'], x['Predicted'])\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "# Plot accuracy by carrier\n",
    "plt.figure(figsize=(10, 6))\n",
    "carrier_accuracy.plot(kind='bar')\n",
    "plt.title('Model Accuracy by Carrier')\n",
    "plt.xlabel('Carrier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze performance by hour\n",
    "hour_accuracy = results_df.groupby('Hour').apply(\n",
    "    lambda x: accuracy_score(x['Actual'], x['Predicted'])\n",
    ")\n",
    "\n",
    "# Plot accuracy by hour\n",
    "plt.figure(figsize=(10, 6))\n",
    "hour_accuracy.plot(kind='line', marker='o')\n",
    "plt.title('Model Accuracy by Hour of Day')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Decision paths analysis\n",
    "# Get the decision path for test samples\n",
    "node_indicator = dt_model.decision_path(X_test)\n",
    "leaf_id = dt_model.apply(X_test)\n",
    "\n",
    "# Count samples in each leaf node\n",
    "leaf_samples = pd.Series(leaf_id).value_counts().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nDecision Tree Path Analysis:\")\n",
    "print(f\"Number of leaf nodes used: {len(leaf_samples)}\")\n",
    "print(f\"Most populated leaf node has {leaf_samples.iloc[0]} samples\")\n",
    "print(f\"Average decision path length: {node_indicator.sum() / len(X_test):.2f} nodes\")\n",
    "\n",
    "# Print insights\n",
    "print(\"\\nDecision Tree Model Insights:\")\n",
    "print(f\"1. Overall model accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"2. Top 3 most important features: {feature_importance['Feature'].iloc[:3].tolist()}\")\n",
    "print(f\"3. Best performing carrier: {carrier_accuracy.index[0]} with accuracy {carrier_accuracy.iloc[0]:.4f}\")\n",
    "print(f\"4. Worst performing carrier: {carrier_accuracy.index[-1]} with accuracy {carrier_accuracy.iloc[-1]:.4f}\")\n",
    "\n",
    "# Compare with training accuracy to check for overfitting\n",
    "y_train_pred = dt_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nOverfitting Check:\")\n",
    "print(f\"Training accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Testing accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Difference: {train_accuracy - test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
